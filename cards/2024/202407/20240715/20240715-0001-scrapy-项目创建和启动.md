# 0001-scrapy-项目创建和启动

## 标签

## 内容

```bash {.line-numbers}
# scrapy startproject 项目名称
scrapy startproject mySpider

# 进入爬虫项目
cd my_spider

# 创建第一个爬虫
# scrapy genspider 爬虫名称 允许爬虫的域名
# 会在 my_spider/spiders 目录下创建 baidu.py
scrapy genspider baidu https://www.baidu.com

# baidu.py 创建一个继承 scrapy.Spider 的 BaiduSpider 类
# 声明3个类属性
# 1. name  爬虫名称
# 2. allowed_domains 允许爬虫的域名
# 3. start_urls 爬取的地址
# 声明一个实例方法 parse, 可以在parse里面编写解析代码

# 在项目目录下执行 scrapy crawl 爬虫名称
scrapy crawl baidu
# 也可以在爬虫文件的 main函数中通过cmdline调用
# --nolog 会屏蔽掉日志，一般不加
cmdline.execute("scrapy crawl baidu --nolog".split())

# 有可能执行失败
# 将scrapy中的Twisted降级到22.10.0版本：
pip install Twisted==22.10.0
```

## 参考
